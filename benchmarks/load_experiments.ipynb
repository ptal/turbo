{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Experiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we start by loading the data collected while running different experiment-wares , and perform some preprocessing on this data to allow its use for further analysis in dedicated notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first need to import the modules we need to load the data.\n",
    "In particular, we must obviously import *Metrics-Wallet*, which we will use to deal with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:26:58.851247Z",
     "start_time": "2021-11-07T17:26:58.847902Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from metrics.wallet import BasicAnalysis\n",
    "import pandas as pd\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step is to read the data from the log files produced by our different experiment-wares.\n",
    "This data is described in the file [`scalpel_config.yml`](config/scalpel_config.yml), and automatically parsed by *Metrics-Scalpel* to create a `BasicAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:27:53.817744Z",
     "start_time": "2021-11-07T17:27:00.267087Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = BasicAnalysis(input_file='config/config.yml', log_level='WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `BasicAnalysis` object instantiated above provides elementary and general methods for preprocessing our data before actually analyzing the results (which will require more specific methods as it can be seen in the dedicated notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['input', 'experiment_ware', 'cpu_time', 'problem', 'status',\n",
       "       'flatBoolConstraints', 'arch', 'flatBoolVars', 'num_solutions',\n",
       "       'store_mem', 'eps_solved_subproblems', 'eliminatedImplications',\n",
       "       'timeout_ms', 'flatIntVars', 'variables', 'flatIntConstraints', 'paths',\n",
       "       'or_nodes', 'solveTime', 'propagator_mem', 'run', 'propagations',\n",
       "       'peakDepth', 'objectiveBound', 'free_search', 'propagators',\n",
       "       'objective', 'stack_size', 'problem_path', 'boolVariables', 'failures',\n",
       "       'solver', 'nodes', 'method', 'memory_configuration',\n",
       "       'fixpoint_iterations', 'restarts', 'and_nodes', 'initTime',\n",
       "       'num_blocks_done', 'nSolutions', 'eps_skipped_subproblems',\n",
       "       'eps_num_subproblems', 'flatTime', 'version', 'shared_mem',\n",
       "       'evaluatedHalfReifiedConstraints', 'evaluatedReifiedConstraints',\n",
       "       'solutions', 'model', 'data_file', 'timeout', 'success', 'user_success',\n",
       "       'missing', 'consistent_xp', 'consistent_input', 'error'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.data_frame.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An important thing to do now is to visualize the collected data, to make sure that everything was properly read.\n",
    "This can be achieved by looking at the data-frame that has been built inside the `BasicAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>success</th>\n",
       "      <th>consistent_xp</th>\n",
       "      <th>consistent_input</th>\n",
       "      <th>error</th>\n",
       "      <th>user_success</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>nfc</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>roster-sickness</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             problem  success  consistent_xp  consistent_input  error  \\\n",
       "338              nfc     True           True              True  False   \n",
       "280  roster-sickness     True           True              True  False   \n",
       "\n",
       "     user_success  missing  \n",
       "338          True    False  \n",
       "280          True    False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.data_frame[(analysis.data_frame['experiment_ware']=='TurboCPU') & (analysis.data_frame['status']=='OPTIMAL_SOLUTION')][['problem','success','consistent_xp','consistent_input','error','user_success','missing']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the success and consistency of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our analysis, we will need to know whether a given experiment was successful. As an example, we provide below the code to check the success of an optimization solver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_success(xp):\n",
    "    \"\"\"\n",
    "    This function checks that a solver either proved the optimality of its best\n",
    "    bound within the time limit, or proved the input to be unsatisfiable.\n",
    "\n",
    "    :param xp: The experiment to determine the best bound of.\n",
    "    \"\"\"\n",
    "    return xp['status'] == 'OPTIMAL_SOLUTION' or xp['status']=='SATISFIED'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that our experiments are consistent, we also need to compare the results obtained by the different experiment-wares. As an example, we provide below the code to check that if different optimization solvers claim to have found an optimal value, this value must be the same for all solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_consistent_by_input(df_input):\n",
    "    \"\"\"\n",
    "    This function checks that the pairwise comparison between two different\n",
    "    optimal bounds found on the same input is small enough to consider these bounds as consistent.\n",
    "    \"\"\"\n",
    "    # Checking the decision of the solvers.\n",
    "    decisions = df_input['status'].unique()\n",
    "    if 'OPTIMAL_SOLUTION' in decisions and 'UNSATISFIABLE' in decisions:\n",
    "        # A solver has found an optimal solution while another proved unsatisfiability.\n",
    "        return False\n",
    "    if 'SATISFIED' in decisions and 'UNSATISFIABLE' in decisions:\n",
    "        # A solver has found a solution while another proved unsatisfiability.\n",
    "        return False\n",
    "\n",
    "    # Checking that at most one optimal value exists.\n",
    "    best_values_for_complete_search = df_input[df_input['objective']=='OPTIMAL_SOLUTIOn']['objective'].unique()\n",
    "\n",
    "    # Checking if the \"proved\" best bound is less optimal than another non-optimal bound\n",
    "    if df_input['method'].unique()[0] == 'minimize': # in the case of minimization\n",
    "        best_global_value = df_input['objective'].min()\n",
    "    else: # in the case of maximization\n",
    "        best_global_value = df_input['objective'].max()\n",
    "    if best_global_value is None or len(best_values_for_complete_search) == 0:\n",
    "        return True\n",
    "    # Checking \n",
    "    return best_values_for_complete_search[0] == best_global_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.check_success(is_success)\n",
    "analysis.check_input_consistency(is_consistent_by_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.error_table()[['problem','experiment_ware','status','method','objective']].to_html(\"error.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Summary and export of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now give a summary of the analysis, that we obtain through the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_experiment_wares</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_inputs</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_experiments</th>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_missing_xp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_inconsistent_xp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_inconsistent_xp_due_to_input</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more_info_about_variables</th>\n",
       "      <td>&lt;analysis&gt;.data_frame.describe(include='all')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     analysis\n",
       "n_experiment_wares                                                          4\n",
       "n_inputs                                                                   88\n",
       "n_experiments                                                             352\n",
       "n_missing_xp                                                                0\n",
       "n_inconsistent_xp                                                           0\n",
       "n_inconsistent_xp_due_to_input                                              0\n",
       "more_info_about_variables       <analysis>.data_frame.describe(include='all')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.description_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the analysis is exported, both to share the data to allow the reproducibility of the analysis, and to reuse it in other notebooks dedicated to more specific analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:31:00.310070Z",
     "start_time": "2021-11-07T17:31:00.293572Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.export('.cache')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
